#! /usr/bin/env python

import math
import cv2
import uuid

import mediapipe as mp
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils

import message_filters
import rospy
from cv_bridge import CvBridge

from std_msgs.msg import Empty
from sensor_msgs.msg import Image, CameraInfo, RegionOfInterest
from hri_msgs.msg import IdsList, RegionOfInterestStamped

DEBUG = False

# if set to true, face IDs will be generated as a sequence of integers,
# starting at 00001.
# Otherwise, face IDs will be a random set of 5 characters in [0-9a-f]
DETERMINISTIC_ID = True

PREALLOCATE_PUBLISHERS = DETERMINISTIC_ID

# nb of pixels between the centers of to successive regions of interest to
# consider they belong to the same person
MAX_ROIS_DISTANCE = 20

# max scale factor between two successive regions of interest to consider they
# belong to the same person
MAX_SCALING_ROIS = 1.2

def _normalized_to_pixel_coordinates(
        normalized_x: float, normalized_y: float, image_width: int,
        image_height: int):

    x_px = min(math.floor(normalized_x * image_width), image_width - 1)
    y_px = min(math.floor(normalized_y * image_height), image_height - 1)
    return x_px, y_px

def distance_rois(bb1, bb2):
    x1, y1 = bb1.x_offset + bb1.width/2, bb1.y_offset + bb1.height/2
    x2, y2 = bb2.x_offset + bb2.width/2, bb2.y_offset + bb2.height/2

    return (x1-x2) * (x1-x2) + (y1-y2) * (y1-y2)

last_id = 1
def generate_face_id():
    if DETERMINISTIC_ID:
        global last_id
        id_str = "%05d" % last_id
        last_id = (last_id + 1) % 10000
        return id_str

    else:
        return str(uuid.uuid4())[:5] # for a 5 char long ID

def generate_tmp_face_id():
    return str(uuid.uuid4())[:5] # for a 5 char long ID


# ID -> (publisher, RoI, nb_frames_visible)
detectedFaces = {}


def find_previous_match(bb):
    for id, value in detectedFaces.items():
        _, prev_bb, _ = value
        if distance_rois(prev_bb, bb) < MAX_ROIS_DISTANCE * MAX_ROIS_DISTANCE \
        and 1/MAX_SCALING_ROIS < prev_bb.width/bb.width < MAX_SCALING_ROIS \
        and 1/MAX_SCALING_ROIS < prev_bb.height/bb.height < MAX_SCALING_ROIS:
            return id
    return None


class FaceDetector:
    def __init__(self):

        self.detector = mp_face_detection.FaceDetection(
                            model_selection=1,
                            min_detection_confidence=0.5)

    def detect(self, img):
        """img is expected as RGB
        """
        img_rows, img_cols, _ = img.shape

        return self.get_boundingboxes(
                        self.detector.process(img).detections,
                        img_cols, img_rows)

    def get_boundingboxes(self, detections, image_cols, image_rows):
        """
        Based on https://github.com/google/mediapipe/blob/master/mediapipe/python/solutions/drawing_utils.py
        """
        res = []
        if not detections:
            return res

        for detection in detections:
            bb = detection.location_data.relative_bounding_box
            x, y = _normalized_to_pixel_coordinates(
                        bb.xmin, bb.ymin,
                        image_cols, image_rows)
            w, h = _normalized_to_pixel_coordinates(
                        bb.width, bb.height,
                        image_cols, image_rows)

            res.append((x,y,w,h))

        return res

    def __str__(self):
        return "Google mediapipe face detector"


facedetector = FaceDetector()
faces_pub = rospy.Publisher("/humans/faces/tracked", IdsList, queue_size=1)
semaphore_pub = rospy.Publisher("/hri_face_detect/ready", Empty , queue_size=1, latch=True)

# holds all the individual face publishers -- only used when pre-allocating face publishers
face_pubs = []

#def callback(rgb_msg, camera_info):
def callback(rgb_msg,):
    global detectedFaces

    image = CvBridge().imgmsg_to_cv2(rgb_msg, desired_encoding="rgb8")
    img_height, img_width, _ = image.shape
    #camera_info_K = np.array(camera_info.K).reshape([3, 3])
    #camera_info_D = np.array(camera_info.D)
    #rgb_undist = cv2.undistort(rgb_image, camera_info_K, camera_info_D)

    bbs = facedetector.detect(image)

    currentFaces = {}
    for bb in bbs:
        x, y, w, h = bb
        bb = RegionOfInterest(max(0, x), 
                              max(0, y), 
                              min(img_height-y, h), 
                              min(img_width-x, w), 
                              True)

        id = find_previous_match(bb)
        if id:
            # we re-detect a face: if it is a 2nd frame, we create a publisher for it.
            if not detectedFaces[id][0]:
                final_id = generate_face_id()
                rospy.loginfo("New face [face_%s]" % final_id)

                if PREALLOCATE_PUBLISHERS:
                    pub = face_pubs[final_id]
                else:
                    pub = rospy.Publisher("/humans/faces/%s/roi" % final_id, RegionOfInterestStamped, queue_size=1)

                currentFaces[final_id] = (pub, bb, detectedFaces[id][2] + 1)
            else:
                currentFaces[id] = (detectedFaces[id][0], bb, detectedFaces[id][2] + 1)
        else:
            # we 'provisionally' store the face - we'll create a publisher and start publishing only if we see the
            # face a second time
            id = generate_tmp_face_id()
            currentFaces[id] = (None, bb, 1)

    # iterate over faces not seen anymore, and unregister corresponding publishers
    for id, value in detectedFaces.items():
        if id not in currentFaces:
            pub, _, nb_frames = value
            if pub:
                rospy.loginfo("Face [face_%s] lost. It remained visible for %s frames" % (id, nb_frames))
                pub.unregister()

    detectedFaces = currentFaces

    list_ids = []

    for id, value in detectedFaces.items():
        pub, bb, _ = value
        if pub:
            list_ids.append(str(id))
            pub.publish(RegionOfInterestStamped(rgb_msg.header, bb))


    faces_pub.publish(IdsList(rgb_msg.header, list_ids))

    if DEBUG:
        # Draw the face detection annotations on the image.
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        for id, value in detectedFaces.items():
            pub, bb, nb_frames = value
            if not pub:
                continue
            cv2.rectangle(image, (bb.x_offset, bb.y_offset), \
                             (bb.x_offset + bb.width, bb.y_offset + bb.height),\
                             (255,255,0), 2)
            cv2.putText(image, id,(bb.x_offset, bb.y_offset), \
                                cv2.FONT_HERSHEY_SIMPLEX, 1,
                                (255,0,0))

    
        cv2.imshow('MediaPipe Face Detection', image)
        cv2.waitKey(5)

if __name__ == '__main__':
   rospy.init_node('hri_face_detect')
   #image_sub = message_filters.Subscriber('/image_raw', Image)
   #info_sub = message_filters.Subscriber('/camera_info', CameraInfo)
   #ts = message_filters.ApproximateTimeSynchronizer([image_sub, info_sub], 10, 0.2)
   #ts.registerCallback(callback)
   image_sub = rospy.Subscriber("image", Image, callback)

   if PREALLOCATE_PUBLISHERS:
        face_pubs = {"%05d" % i : rospy.Publisher("/humans/faces/%05d/roi" % i, RegionOfInterestStamped, queue_size=1) for i in range(1,30)}

   rospy.loginfo("Ready. Waiting for images to be published on %s." % image_sub.name)
   semaphore_pub.publish(Empty())

   rospy.spin()

